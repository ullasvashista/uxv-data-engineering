{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06d93d88-f226-41d9-bf0a-a3195a37dc44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "* Project: Ontology Management Platform\n",
    "* Author: Ullas Vashista\n",
    "* Last Update: 05/01/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef2d51ae-da1f-4bf8-a0cd-d64ba8ada12a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "import re\n",
    "import configparser\n",
    "import time\n",
    "from delta.tables import DeltaTable\n",
    "import os\n",
    "import asyncio\n",
    "from azure.eventhub.aio import EventHubConsumerClient\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6673f7f-ff41-4310-a311-9b4c01a59250",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ------------------- CONFIG -------------------\n",
    "# Create parser and read config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../config/config.ini\")\n",
    "\n",
    "# Read values\n",
    "# EventHub - Source\n",
    "metadata_connection_str = config.get(\"SourceEventHub\", \"metadata_connection_str\")\n",
    "metadata_consumer_group = config.get(\"SourceEventHub\", \"metadata_consumer_group\")\n",
    "metadata_eventhub_name      = config.get(\"SourceEventHub\", \"metadata_eventhub_name\")\n",
    "\n",
    "# Storage - Target\n",
    "logm_storage_account_name = config.get(\"TargetStorage\", \"account_name\")\n",
    "logm_container_name       = config.get(\"TargetStorage\", \"container_name\")\n",
    "logm_mount_name           = config.get(\"TargetStorage\", \"mount_name\")\n",
    "\n",
    "#Key Vault Scope Name\n",
    "KeyVaultScope = config.get(\"KeyVaultScope\", \"scope_name\")\n",
    "tenant_id = config.get(\"KeyVaultScope\", \"tenant_id\") # This retrieves a secret value (e.g., from a key vault). It won't display the actual value when printed (shows [REDACTED]) but works correctly when used in code. For testing or display purposes, use: tenant_id = \"<actual_tenant_id>\"\n",
    "\n",
    "# Define path to your Delta table\n",
    "metadata_final_table           = config.get(\"TargetStorage\", \"metadata_final_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e12829bd-c820-4c5a-ba0a-23d5e6a2b525",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Secrets\n",
    "client_id     = dbutils.secrets.get(scope=KeyVaultScope, key=\"adls-client-id\")\n",
    "client_secret = dbutils.secrets.get(scope=KeyVaultScope, key=\"adls-client-secret\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc11e5c4-ad02-4aeb-af7b-d803ac9b6fa4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Spark Configuration for ADLS Mounting\n",
    "def configure_spark_for_adls_oauth(storage_account_name, client_id, client_secret, tenant_id):\n",
    "    spark.conf.set(f\"fs.azure.account.auth.type.{storage_account_name}.dfs.core.windows.net\", \"OAuth\")\n",
    "    spark.conf.set(f\"fs.azure.account.oauth.provider.type.{storage_account_name}.dfs.core.windows.net\", \n",
    "                   \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "    spark.conf.set(f\"fs.azure.account.oauth2.client.id.{storage_account_name}.dfs.core.windows.net\", client_id)\n",
    "    spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{storage_account_name}.dfs.core.windows.net\", client_secret)\n",
    "    spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{storage_account_name}.dfs.core.windows.net\", \n",
    "                   f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a54094ff-fe73-4f10-9ec1-66ff55ea582f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Message buffer\n",
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9b7789f-951d-4ebb-bbe8-2c39f2fedc90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Event handler\n",
    "async def on_event(partition_context, event):\n",
    "    try:\n",
    "        if event is None:\n",
    "            print(\"Received None as event.\")\n",
    "            return\n",
    "\n",
    "        body_str = event.body_as_str()\n",
    "        #print(\"Received raw body:\", body_str)\n",
    "\n",
    "        try:\n",
    "            body = json.loads(body_str)\n",
    "            messages.append(body)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Skipping invalid JSON: {body_str}\")\n",
    "\n",
    "        await partition_context.update_checkpoint(event)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing message: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "752c4975-f36a-40ef-8250-839090ef42fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Receiver\n",
    "async def main():\n",
    "    client = EventHubConsumerClient.from_connection_string(\n",
    "        conn_str=metadata_connection_str,\n",
    "        consumer_group=metadata_consumer_group\n",
    "    )\n",
    "\n",
    "    async with client:\n",
    "        print(\"Listening for events...\")\n",
    "        await client.receive(\n",
    "            on_event=on_event,\n",
    "            starting_position=\"-1\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e37f8af4-f68e-4b63-9d23-273f87a60f29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for events...\n⏰ Done listening. Moving to DataFrame creation.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Force the listener to stop after 10 seconds\n",
    "try:\n",
    "    await asyncio.wait_for(main(), timeout=10)\n",
    "except asyncio.TimeoutError:\n",
    "    print(\"⏰ Done listening. Moving to DataFrame creation.\")\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "df = pd.DataFrame(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99a5fe39-3f85-4745-8dc2-52a6433dd88a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def transform_load():\n",
    "    raw_df = spark.createDataFrame(df)\n",
    "\n",
    "    # Add source_dir\n",
    "    raw_df = raw_df.withColumn(\"TimeGenerated\", current_timestamp())\n",
    "    cur_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    raw_df = raw_df.withColumn(\"input_file_path\", lit(f\"{metadata_eventhub_name}-{cur_time}\"))\n",
    "\n",
    "    #Add Metadata Columns\n",
    "    final_df = (\n",
    "        raw_df\n",
    "        .withColumn(\"body\", to_json(struct(*raw_df.columns)))\n",
    "        .withColumn(\"MetadataLogId\", sha2(col(\"body\"), 512).cast(\"string\"))\n",
    "        .drop(\"body\")\n",
    "        .withColumn(\"MetadataLogType\", lit(\"logm.omp.metadata\"))\n",
    "        .withColumn(\"MetadataLogTimeGenerated\", col(\"TimeGenerated\").cast(TimestampType()))\n",
    "        .withColumn(\"MetadataLogDate\", date_format(col(\"TimeGenerated\"), \"yyyyMMddHHmmssSSS\").cast(LongType()))\n",
    "        .drop(\"TimeGenerated\")\n",
    "        .withColumn(\"TimeGenerated\", current_timestamp().cast(StringType()))\n",
    "        .withColumn(\"MetadataLogWindow\", date_format(from_utc_timestamp(col(\"MetadataLogTimeGenerated\"), \"UTC\"), \"yyMMddHHmm\").cast(LongType()))\n",
    "        .withColumn(\"MetadataLogGuid\", concat(col(\"MetadataLogWindow\"), lpad(monotonically_increasing_id(), 9, \"0\")).cast(LongType()))\n",
    "        .drop(\"MetadataLogWindow\")\n",
    "        .withColumn(\"MetadataLogFileName\", col(\"input_file_path\"))\n",
    "        .drop(\"input_file_path\")\n",
    "        .withColumn(\"TenantId\", lit(tenant_id))\n",
    "        .withColumn(\"Type\", lit(\"LOGM_OMP_MEATADATA_CL\"))\n",
    "        )\n",
    "    \n",
    "    # Write to Delta\n",
    "    configure_spark_for_adls_oauth(logm_storage_account_name, client_id, client_secret, tenant_id)\n",
    "\n",
    "    # Check if Delta table exists\n",
    "    if not DeltaTable.isDeltaTable(spark, metadata_final_table):\n",
    "        # Table doesn't exist – write initial data\n",
    "        final_df.write \\\n",
    "            .format(\"delta\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .save(metadata_final_table)\n",
    "\n",
    "    else:\n",
    "        # Table exists – perform MERGE\n",
    "        delta_table = DeltaTable.forPath(spark, metadata_final_table)\n",
    "\n",
    "        delta_table.alias(\"target\").merge(\n",
    "            source=final_df.alias(\"source\"),\n",
    "            condition=\"target.ontology = source.ontology\"\n",
    "        ).whenMatchedUpdateAll() \\\n",
    "        .whenNotMatchedInsertAll() \\\n",
    "        .execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3eaa34ad-7627-4254-b19f-56718eb14d3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ------------------- MAIN -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "891981c6-84e2-49aa-85c0-b7edfcfcee82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Data Loaded\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    transform_load()\n",
    "    print(\"New Data Loaded\")\n",
    "except Exception as e:\n",
    "    print(\"No new data from EventHub\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8028297115607970,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ETL_EventHub_omp_Metadata",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}